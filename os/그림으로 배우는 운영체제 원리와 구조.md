
# 컴퓨터 시스템 구성요소

> 운영체제가 컴퓨터 시스템에서 어떤 일을 하나요?

- 운영체제는 컴퓨터 하드웨어 시스템과 사용자 간의 인터페이스를 담당한다.  컴퓨터 시스템을 효율성을 향상시키고 사용자에게 편리한 사용환경을 제공해주는 시스템 소프트웨어

## 1. 프로세서

- 컴퓨터 각 부분의 동작을 제어하고 연산을 수행한다.
- 레지스터, 산술논리 연산장치, 제어장치 등으로 구성된다.

## 2. 버스

- 프로세서를 비롯해 각 장치 간 또는 서브시스템을 서로 연결하여 데이터를 주고받을 수 있게 해주는 통로
- 내부 버스는 **프로세서 내부**에서 레지스터, 연산장치, 메모리와의 인터페이스 등을 연결
- 외부 버스는 프로세서와 입출력장치 등을 연결하고, 시스템 버스라고도 불리며 시스템 버스는 버스 제어기라고 불리는 제어회로를 가지고 있다.
- 외부 버스는 메모리 버스, 주변 버스(데이터 버스, 주소 버스, 제어 버스) 가 있다.

<!-- more -->
## 3. 레지스터

- 프로세서에 위치한 고속 메모리로 프로세서가 바로 사용할 수 있는 데이터를 담는다.
- 저장되는 데이터의 종류에 따라 **데이터 레지스터, 주소 레지스터, 상태 레지스터**로 나뉜다.

## 4. 메모리

- 데이터를 저장하기 위해 사용하고 일반적으로 메모리 계층 구조를 이룬다.
- 레지스터 → 캐시 → 메인 메모리→ 자기디스크 → 광학디스크 → 자기테이프
- 메모리 계층 구조는 다양한 레벨의 메모리를 연결하여 비용, 용량, 접근 시간 등을 상호 보완한 것이다.

### 캐시

- 처리 속도가 빠른 프로세서와 상대적으로 느린 메인 메모리 사이에서 데이터나 정보를 저장하는 고속 버퍼이다.

## 5. 인터럽트

- 현재 실행 중인 프로그램의 수행을 미루고 다른 프로그램의 수행을 요구하는 명령이다.
- 시스템 처리 효율을 향상시키기 위해 사용되며 프로그램이 실행 순서를 바꿔가며 처리하기 때문에 다중 프로그래밍이 가능하다.

# 운영체제 소개

## 커널

- 운영체제 핵심으로 메모리에 상주하면서 응용 프로그램 수행에 필요한 환경을 설정하는 소프트웨어
- 응용 프로그램 실행에 필요한 서비스를 제공하고 실행되는 프로세스를 스케쥴링하는 역활을 한다.

## 운영체제의 목적

- 사용자가 프로그램을 개발하고 사용하는데 좀 더 편리한 환경을 제공하기 위해
- 계산 시스템의 성능 및 효율성 향상

## 운영체제의 역활

- 운영체제는 시스템 운영 요소를 적절하게 사용할 수 있도록 제어하며, 프로그램 실행환경과 필요한 자원(프로세스, 메모리, 파일, 장치)를 제공하고 관리해주며, 다양한 입출력장치와 사용자 프로그램을 제어한다.

## 운영체제의 기능

- 메모리, 보조기억장치, 프로세스, 장치, 파일 관리, 시스템 보호, 네트워킹, 명령 해석기 시스템 관리 등의 기능을 한다.

### 시스템 호출

- 실행 중인 프로그램과 운영체제 간의 인터페이스로, 운영체제의 기능을 서비스 받는다.
- 프로세스 제어, 파일 조작, 장치 조작, 정보 관리, 통신 등

> 시스템을 계층으로 나누면 시스템 설계나 구현이 단순해진다. 각 계층은 자신보다 하위 계층이 제공하는 연산만 사용해 구현하면 된다. 따라서 해당 계층은 이런 연산이 어떻게 수행되는지 알 필요 없고, 연산이 무엇을 하는 지만 알면 된 다. 시스템 검증과 오류 수정이 쉽다.

# 프로세스와 스레드

## 프로세스

- 실행 중인 프로그램
- 실행 중인 프로그램이란 디스크에 저장되어 있던 실행 가능한 프로그램이 메모리에 적재되어 운영체제의 제어를 받는 상태

### 프로세스 주소 공간

- 실행 스택 : 호출된 함수의 복귀 주소와 지역 변수처럼 일시적인 데이터를 저장하는 영역
- 실행 힙 : 코드 영역과는 별도로 유지되는 자유 영역이다. 프로그램 실행 중 시스템 호출을 통해 사용되다가 해지되는 등 자유자재로 사용할 수 있다.
- 데이터(정적 변수) : 프로세스 실행 중에 동적으로 할당받는 영역으로 전역 또는 정적 변수를 저장한다.
- 코드 : 프로세스가 실행되는 코드를 저장한다.

### 프로세스 제어 블록(PCB)

- 프로세스를 관리하기 위해 유지되는 데이터 블록이다.
- 프로세스 식별자, 프로세스 상태, 프로그램 카운터, 스케줄링 정보, 입출력 상태 정보 등으로 구성된다.
- 프로세스를 생성할 때 만들어지고, 메인 메모리에 유지되며, 프로세스가 종료될 때 삭제된다.
- **프로세스 식별자** : 각 프로세스에 대한 고유 식별자를 지정한다.
- **프로세스 상태** : 생성, 준비, 대기, 중단 등의 상태를 표시한다.
- **레지스터 저장 영역** : 누산기, 인덱스 레지스터, 범용 레지스터, 조건 코드 등에 관한 정보로 컴퓨터 구조에 따라 수나 형태가 달라진다. 인터럽트가 발생하면 프로그램 카운터와 함께 저장되어 다시 실행될 때 원상 복귀할 수 있게 한다.
- **계층 정보** : 프로세서 사용시간, 실제 사용시간, 상한시간, 계정 번호 등
- **입출력 상태 정보 :** 특별한 입출력 요구 프로세스에 할당된 입출력장치, Open된 파일의 목록 등
- **메모리 관리 정보** : 메모리 영역을 정의하는 하한 및 상한 레지스터 또는 페이지 테이블 정보

### 프로세스 생성 과정

- **1단계** : 새로운 프로세스에 프로세스 식별자를 할당한다.
- **2단계 :** 프로세스의 모든 구성 요소를 포함할 수 있는 주소 공간과 프로세스 제어 블록 공간을 할당한다.
- **3단계** : 프로세스 제어 블록을 초기화한다. (프로세스의 상태 정보/ 프로그램 카운터/ 스택 포인터 등의 초기화)
- **4단계**: 실행 준비 큐에 삽입한다.

> **프로세스 우선 순위 변경**
우선순위가 낮은 프로세스에는 시간 할당량을 크게 제공하고, 우선순위가 높은 프로세스는 시간 할당량을 적게 제공한다.
입출력 중심의 프로세스는 프로세서를 아주 짧게 사용하고, 프로세스 중심 프로세스는 프로세서 사용 횟수는 적지만 한번에 오래 사용하게 하여 균형을 맞춘다.

## 문맥교환 (Context Switching)

- 프로세스를 다른 프로세스로 교환하기 위해 이전 프로세스의 상태 레지스터 내용을 보관하고 다른 프로세스의 레지스터를 적재해야 하는데 이런 일련의 과정을 **문맥교환**이라고 한다.
- **입출력 인터럽트** : 입출력 동작이 발생한 사실을 확인 후 이벤트를 기다리는 프로세스를 준비상태로 바꾸고 실행한 프로세스를 결정한다.
- **클록 인터럽트** : 현재 실행 중인 프로세스의 할당 시간을 조사하여 실행 중인 프로세스를 준비 상태로 바꾸고 다른 프로세스를 디스패치하여 실행 상태로 바꾼다.

## 스레드

- 프로세스가 작업 흐름이라면 스레드는 프로세스 내의 명령어를 독립적으로 수행할 수 있는 실행 흐름
- 같은 그룹의 스레드와 코드, 주소 공간, 운영체제의 자원 등을 공유
- 스레드는 스레드 실행 상태, 실행 스택, 지역 변수와 스레드별 정적 저장소(레즈스터), 프로세스의 메모리와 자원에 대한 접근과 같은 스레드 실행 환경 정보
- 프로세스의 코드, 데이터, 힙 영역을 공유받는다.

### 스레드 사용 이점

- 사용자에 대한 응답성 증가
- 프로세스 자원과 메모리 공유 가능 → 메모리와 파일을 공유하므로 자원 생성과 관리의 중복성을 최소화하여 실행 능력 향상
- 다중 프로세서 구조 활용 가능 → 각 스레드는 다른 프로세서에서 병렬로 실행 가능

# 병행 프로세스와 상호배제

## 병행 프로세스

- 프로세스 여러 개가 동시에 실행되면 병행 프로세스라고 한다. 병행 프로세스는 서로 관련 없이 독릭접으로 수행할 수도 있고 다른 프로세스와 협력하면서 기능을 수행하기도 한다

## 선행 제약

- 프로세스가 순서대로 다른 상태로 옮겨가는 것을 선행 제약이라고 한다.

## 동기화 문제점

- 상이한 동기화 문제점(유한 버퍼문제, 생산자/소비자 문졔)은 병행 제어 문제들의 실례들이기 때문에 중요하다.

## 상호배제(Mutual Exclusion)

- 프로세스 하나가 공유 데이터에 접근하는 동안 다른 프로세스가 해당 데이터를 접근할 수 없게 하는 것을 상호배제(Mutual Exclusion)라고 한다.
- 공유자원을 동시에 사용하지 못하게 실행을 제어하는 기법을 **프로세스 동기화**라고 한다.

## 경쟁상태(Race Condition)

- 공유 데이터에 대한 접근 순서에 따라 실행 결과가 달라지는 상황

## 임계영역

- 둘 이상의 프로세스가 공유할 수 없는 자원을 임계 자원이라고 하고, 프로그램에서 임계 자원을 이용하는 부분을 임계 영역이고 한다.
- 다수의 프로세스가 접근 가능한 영역이면서 한 순간에 하나의 프로세스만 사용할 수 있는 영역
- 임계영역 문제는 프로세스들이 서로 협력하여 자원을 사용할 수 있도록 프로토콜을 설계함으로써 해결할 수 있다.

```c
while(1){
	**진입영역**
	임계영역
	**출구영역**
	잔류영역
}

```

- 임계영역 문제를 해결하기 위해서는 다음 세 가지 요구를 만족해야한다.

    **1. 상호 배제 :** 프로세스 Pi가 임계영역에서 수행 중일 때 다른 프로세스는 임계영역에서 수행할 수 없다.

    **2. 진행** : 임계영역에서 수행하는 프로세스가 없고 여러 개의 프로세스가 임계영역으로 들어갈려고 하면 프로세스 선정 알고리즘에 따라 다음 임계영역에서 수행할 대상을 선정한다. 다음 임계영역으로 들어갈 프로세스 선택은 무한정 미룰 수 없다.

    **3. 제한된 대기** : 한 프로세스가 임계영역을 요청한 후 요청이 수락되기전까지 다른 프로세스가 임계영역에 진입할 수 있는 횟수를 제한해야 한다.

- 상호배제에 대한 요구 조건을 만족시키기 위해 소프트웨어적인 방법, 하드웨어적인 방법, 운영체제와 프로그래밍 언어의 도움을 받은 방법 등이 있다.

### 소프트웨어적인 임계영역 해결

- 데커알고리즘, 세마포어

## 세마포어

- 상호배제의 해결책에 대한 주요 단점은 이들이 모두 바쁜 대기를 요구한다는 점이다. 세마포어는 이러한 어려움을 극복했다.

## 임계영역과 모니터

- 운영체제는 타이밍 오류에 대처할 수 있는 수단을 제공해야 한다. 임계영역은 상호배제와 임의의 동기화 문제들을 안전하고 효과적으로 구현하기 위하여 사용된다. 모니터는 추상 데이터 형태를 공유하기 위해 동기화 메커니즘을 제공한다.
- 

[https://messin9032.tistory.com/entry/간단한-OS-설명](https://messin9032.tistory.com/entry/%EA%B0%84%EB%8B%A8%ED%95%9C-OS-%EC%84%A4%EB%AA%85)

# 교착상태와 기아상태

## 교착상태

- 멀티 프로그래밍 시스템에서 결코 일어나지 않을 사건을 프로세스가 기다리고 있는 것을 말한다.
- 예 ) 프로세스 P : DVD 드라이브 점유 → 프린터 요청

             프로세스 Q : 프린터 점유 → DVD 드라이브 요청

## 교착상태 발생 조건

교상상태는 시스템에서 다음 네 가지 조건이 동시에 발생할 때 발생한다.

- **상호배제 :** 한 번에 한 프로세스만 해당 자원을 사용할 수 있어야 한다. 만일, 사용 중인 자원을 다른 프로세스가 사용하려면 요청한 자원이 해제될 때까지 기다려야 한다.
- **점유와 대기** : 최소한 자원 하나를 보유하고 다른 프로세스에 할당된 자원을 얻기 위해 기다리는 프로세스가 있어야 한다.
- **비선점** : 자원은 선점될 수 없다. 즉 자원을 강제로 빼앗을 수 없으며 자원을 점유하고 있는 프로세스가 끝나야 해제된다.
- **순환대기** : 각 프로세스가 순환적으로 다음 프로세스가 요구하는 자원을 가지고 있는 것

## **교착상태(Deadlock) 해결 방법**

교착상태 해결 방법에는 예방, 회피, 회복, 무시의 4가지가 있다.

**1. 예방 (Prevention)**

교착상태 발생 조건은 위의 네 가지 경우를 모두 만족시켰어야 했다. 교착상태를 해결하기 위해서는 네 가지 조건 중 하나만 해결을 하면 된다.

**2. 회피 (Avoidance)**

교착상태의 발생조건을 없애기보다는 발생하지 않도록 알고리즘을 적용하는 방법으로, 자원할당 그래프 알고리즘과 은행원 알고리즘이 있다.

**3. 회복 (Recovery)**

교착상태가 발생하는 것을 아예 막지 않고, 만약 교착상태가 발생하면 발생 이후에 문제를 해결하는 방법

**4. 무시 (Ignore)**

교착상태를 해결할때에도 [문맥교환](http://junsday.tistory.com/27)에 의한 오버헤드로 성능 저하가 생긴다. 교착상태에 의한 성능 저하보다 이를 해결할 때의 성능저하가 큰 경우 그냥 무시한다.

## 교착상태 예방 기법

- **상호배제 조건 방지** : 자원을 공유 가능하게 한다. 하지만 어떤 자원은 공유 자체가 불가능하다. 예를 들면, 파일 쓰기는 배타적인 접근만이 허용되기 때문에 상호배제 조건을 거부하면 교착상태를 예방하는 것이 불가능하다.
- **점유와 대기 방지** : 프로세스 대기를 없애려면 프로세스가 실행되기 전에 필요한 모든 자원을 할당함 또는 프로세스가 자원을 점유하지 않은 상태에서만 자원을 요청할 수 있도록 함.

 → 자원의 효율성이 낮고 기아상태가 발생 할 수 있음.

- **비선점 조건 방지 :** 이미 할당된 자원에 대한 선점권이 없어야 한다. 요청한 자원을 즉시 할당받을 수 없다면 현재 가진 자원을 모두 해제해야 한다.

       프로세스가 어떤 다른 자원을 요구 할때 요청한 자원을 사용 가능 한지 검사하여, 사용 가능하다  면 점유하고 있는 자원을 반납하고 자원을 할당한다. 사용할 수 없다면 대기 프로세스가 요청한 자원을 점유하고 있는지 검사하여, 대기 프로세스가 가지고 있다면 선점하고, 실행 중인 프로세스가 점유하고 있다면 대기한다

- **환형 대기 부정 :** 모든자원에 대하여 일련의 순서대로 고유번호 부여

각 프로세스는 현재 점유중인 자원의 고유번호를 기준으로 앞이나 뒤 어느 한방향으로만 자원을 요구함

## 교착상태 회피 기법

- 교착상태 예방 기법은 장치의 효율성을 낮추고 시스템 처리량을 감소시키는 결과를 초래한다.
- 회피 기법은 교착상태의 예방보다 덜 엄격한 조건을 요구함으로써 자원을 좀 더 효율적으로 이용하기 위한 것
- 회피 기법은 교착상태가 일어날 가능성을 인정하고 교착 상태가 일어나려고 할 때 적절히 피하는 것
1. **프로세스 시작 거부 :** 프로세스의 요구가 교착상태를 일으킬 수 있다면 프로세스 시작을 중지한다.
2. **자원 할당의 거부** : 프로세스가 요청한 자원을 할당할 때, 교착상태가 발생할 수 있다면 요청한 자원을 할당하지 않는다. 일반적으로 은행가 알고리즘이라고 한다.

### 은행가 알고리즘

- 교착상태를 회피하기 위한 방법으로 다익스트라가 제안하였다. 은행가 알고리즘은 각 프로세스에 자원을 어떻게 할당한 것인가라는 정보가 필요하다. 따라서 각 프로세스가 요청하는 자원 종류의 최대수를 알아야 한다.

### 교착상태 탐지 알고리즘

// Todo

## 교착상태 회복 기법

### 1. 프로세스 중지

- **교착상태 프로세스를 모두 중지** : 교착상태의 순환대기를 확실히 해결했지만 자원 사용과 시간 면에서 비용이 많이 든다.
- **한 프로세스 씩 중지** : 한 프로세스가 중지할 때마다 교착상태 탐지 알고리즘을 호출하여 프로세스가 교착상태에 있는지 확인한다. 알고리즘 호출에 대한 부담이 상당히 크다는 게 단점

### 2. 자원 선점

자원 선점을 이용해 교창상태를 해결하려면, 프로세스의 자원을 선점하여 교착상태가 해결될 때까지 선점한 자원을 다른 프로세스에 할당해야 한다. 교착상태 처리를 위해 선점권을 이용하려면 다음 세가지를 해결해야 한다.

- **선점 자원 선택** : 프로세스를 종료할 때, 비용을 최소화하기 위해 적절한 선점 순서를 정해야 한다.
- **복귀** : 필요한 자원을 잃은 프로세스는 정상적으로 실행할 수 없다. 그러므로 프로세스 상태 정보를 유지해야 한다.
- **기아 :**  프로세스가 짧은 시간 동안만 희생자로 지정됨을 보장해야 한다.

**교착상태를 처리하는 기본 방식은 방지,회피,탐지 기법이 있다. 한가지 방법만으로 운영체제에서 발생되는 모든 자원 할당 문제를 해결하는 것은 불가능하다. 따라서 세 가지 방법을 결합하여 자원 형태마다 최적의 접근 방식을 채택하는 자원의 계층적 순서를 활용한다.**

예를들면, PCB같은 시스템이 사용하는 내부 자원은 자원 순서화에 의한 방지 기법을 이용할 수 있고, 메인 메모리 자원은 선점을 통한 방지 기법, 작업(파일) 자원은 회피 기법을 사용할 수 있다.

## 기아상태

- 교착상태가 자원을 자유롭게 할당한 결과라면 기아상태는 교착상태를 예방하기 위해 자원을 할당할 때 발생(기다림)되는 결과이다.

# 단일 프로세서 스케줄링

## 스케쥴링 개요

### 스케줄링 개념

- 프로세서의 효율을 높이고 시스템의 작업 처리능력을 향상시키며 작업 응답 속도를 최소화하기 위해 사용한다.
- 프로세스를 프로세서에 할당하는 일련의 과정

### 스케줄링 단계

```jsx
시스템에 들어오려고 대기 하는 작업
         |
         |
         |
개시를 기다리는 작업 --------------------------------------------------
         |
         |                                            1단계 스케줄링
         |
활성화 되길 기다리며 보류된 프로세스들----------------------------------
         |       |
         |       |                                    2단계 스케줄링
         |       |
활성화될 수 있는 프로세스들 -------------------------------------------
         |       |
         |       |                                    3단계 스케줄링
         |       |
실행 중인 프로세스들 --------------------------------------------------
         |
         |
     작업 완료
```

- **1단게 : 작업 스케줄링 (어떤 프로세스를 준비큐에 넣을 것인가 ?)**

시스템 자원을 실제 사용할 작업을 결정하는 단계다. 일반적으로 새로운 프로세스가 생성되면 실행된다. (장기 스케줄링)

- **2단계 : 작업 승인과 프로세서 할당 (메모리에 적재된 프로세스 수 관리)**

어느 프로세스에 프로세서를 사용할 수 있는 권한을 줄 것인지를 결정한다. (중기 스케줄링)

- **3단계 : 준비상태의 프로세서에 프로세스 할당 (어떤 프로세스에게 cpu를 할당해 줄 것인가 ?)**

디스패처에 의해 준비상태에 있는 프로세스의 프로세서를 어느 프로세스에 할당할지 결정하는 단계이다. (단기 스케줄링)

### 스케줄링 시 고려사항

- **자원 할당의 공정성**
- **단위 시간단 처리량**
- **응답시간**
- **예측 가능성**
- **과부하**
- **자원 사용의 균형**
- **응답시간과 자원의 활용 간에 균형 유지**
- **실행 대기**
- **우선 순위**
- **서비스 사용 기회**
- **서비스 수**

### 스케줄링 큐

- 스케쥴링을 위해 사용하는 데이터베이스는 큐로 구성되며 프로세스들의 PCB가 리스트 형태로 연결되어 있다.

### 선점 스케줄링과 비선점 스케줄링

- 한 프로세스가 자원을 선택했을 때, 다른 프로세스에 할당된 자원을 빼앗을 수 없는 스케줄링을 비선점이라고 한다.
- 현재 실행 중인 프로세스를 인터럽트할 수 있거나 준비 상태로 이동시킬 수 있다면 선점이라 한다.

### 알고리즘 성능 평가 기준

- **프로세서 사용률** : 프로세서를 실행상태로 항상 유지하여 유휴상태가 되지 않도록 한다.
- **처리율** : 단위 시간당 완료되는 작업 수가 많도록 짧은 작업을 우선 처리하거나 인터럽트 없이 작업을 실행한다.
- **반환시간** : 작업이 시스템에 맡겨져서 메인 메모리에 들어가기까지의 시간, 준비 큐에 있는 시간, 실행 시간, 입출력시간 등 작업 제출 후 완료되는 시간까지의 소요시간이 최소화되도록 한다.
- **대기시간** : 작업의 실행시간이나 입출력시간에는 실제적인 영향을 미치지 못하므로, 준비 큐에서 기다리는 시간이 최소화되도록 사용자 수를 제한한다.

## 스케쥴링 알고리즘

### 1. 선입선처리 알고리즘 (FCFS, First-Come-First=Served)

- 프로세서를 요구하는 순서로 프로세서를 할당하는 방법
- FIFO(First-In First-Out) 큐로 구현한다.
- 일괄처리 시스템에서는 효율적이나 대화식 시스템에서는 사용자가 빠른 응답을 요구하기 때문에 적합하지 않다.

### **2. 최소 작업 우선 스케줄링(SJF, Shortest Job First)**

- 프로세서 버스트 시간이 가장 짧은 작업에 프로세서를 할당하는 기법이다.
- 최소 작업 우선 알고리즘이 최적의 알고리즘으로 평가 받을 수 있으나 단기 스케쥴링에서는 다음 프로세스의 프로세서 버스트 시간을 예상할 수 없기 때문에 근사치를 사용한다.
- 선점형과 비선점형이 있지만 시분할 시스템에서 비선점 스케쥴링은 사용하기 적합하지 않다.
- 선점형 최소 작업 우선 스케쥴링을 최소 잔여 시간 우선 스케쥴링(SRTF)라 한다.

### **3. 우선순위 작업 스케줄링(Priority Scheduling)**

- 현재 실행 중인 프로세스의 우선순위를 비교하여 최고 우선순위를 가진 프로세스에 프로세서를 할당한다.
- 우선순위는 내부적, 외부적으로 정의할 수 있다.
- 내부적 요인은 제한시간, 기억장소 요구량, 사용 파일 수, 평균 프로세서 버스트에 대한 평균 입출력 버스트의 비율
- 외부적 요인 프로세스의 중요성, 사용료를 많이 낸 사용자, 작업을 지원하는 부서, 정책적인 요인 등
- 선점, 비선점형이 있다.
- 우선순위 작업 스케줄링의 문제점은 무한정지와 기아문제가 있다.
- 실행 준비가 되어있으나 우선순위가 높은 프로세스들이 계속 들어오면서 우선 순위가 낮은 프로세스들은 무한정 기다려야 된다.
- 기다림을 해결할 수 있는 방법으로 에이징이 있다.
- 에이징이란 오랫동안 시스템에서 대기하는 프로세스들의 우선순위를 점진적으로 증가시키는 기법이다.

### **4. 순환 할당 스케쥴링(Round-Robin)**

- 시간 할달량(Time Slice) 정의하고, 준비 큐를 순환 큐로 설계하여 프로세서 스케줄러가 준비 큐를 돌아가면서 한번에 한 프로세스에 정의된 규정 시간량 만큼 프로세서를 제공한다.
- 인터럽트를 통해 컨텍스트 스위칭이 발생한다.

### **5. 다단계 큐 스케쥴링**

- 다양한 종류의 프로세스들에 대하여 상이한 알고리즘을 사용하는 것이다. 가장 보편적인 것은 전면작업 대화식 큐로서 순환할당 스케쥴링을 사용하고, 후면작업 일괄처리 큐로써 선입선처리 스케쥴링을 이용한다.

# 메모리 관리

## 메모리 관리 개념

### 메모리 관리 기법

- 컴퓨터 핵심 자원인 메모리의 효과적인 관리를 위해 메모리 할당 기법을 다음 세 가지 측면으로 구분할 수 있다.

 **1. 반입 정책**

  반입 정책은 페이지를 메인 메모리로 가져올 시기를 결정하는 것 이다.

  **요구 반입 기법** : 다음에 실행할 프로세스를 참조요구에 따라 메인 메모리에 적재하는 방법

  **예상 반입 기법** : 시스템의 요구를 예측하여 메모리에 미리 적재 하는 방법

**2. 배치 정책**

 ****디스크에서 반입한 프로세스를 메인 메모리 어느 위치에 저장할 것인가를 결정하는 방법이다.

최초 적합, 최적 적합, 최악 적합 등이 있다.

**3. 대치 정책**

 ****재배치 기법으로 메인 메모리에 있는 어떤 프로세스를 제거할 것인가를 결정한다. 

### 메모리 해석에 대한 두 가지 관점

- 실제 데이터나 프로그램이 저장되는 공간이 물리적 공간
- 프로그래머가 프로그래밍에 사용하는 공간인 논리적 공간
- 논리적 주소와 물리적 주소를 연결은 메모리 매핑(Memory Mapping)을 통해서 이루어지며, 메모리 관리 장치(MMU, Memory Management Unit)로 알려진 하드웨어에서 실행된다.
- 메모리 관리 방식에 따라 여러가지 맵핑 방법이 있으나 일반적으로 고정 분할, 동적 분할, 페이징, 세그먼트, 페이지화된 세그먼트 방식으로 구분한다.

### 메모리 관리 방식

**1. 연속메모리 할당 방식**

- 각 프로그램이 연속된 하나의 블록을 차지하도록 할당
- 직접 배치, 오버레이, 분할 기법 등
- 고정 분할 기법은 메모리의 낭비(내부 단편화) 문제로 동적 분할 메모리 할당 방식이 제안되었다.

**2. 분산 메모리 할당 방식**

- 사용자 프로세스가 페이지나 세그먼테이션 등의 단위로 보조기억장치에 적재되어 있다가 프로세스의 요구에 의해 메인 메모리의 여러 영역에 할당되는 방식이다.
- 이 방식은 가상 메모리 관리 기법으로 발전하였다.

### 주소바인딩

- 고급 언어를 통해 변수라는 개념으로 주소를 표시하는데, 이러한 주소를 논리적 주소라고 하며 논리적 주소를 물리적 주소로 변환하는 과정을 바인딩(Binding)이라고 한다.
- 메모리 주소공간에서 명령어와 데이터 바인딩은 그 방식에 따라 다음과 같이 단계별로 구분된다.

  

  **1. 컴파일**

  프로세스가 메모리 내에 적재될 위치를 컴파일 과정에 알 수 있다면 컴파일러는 물리적 주소를 생성할 수 있다. 이와 같은 과정을 **절대 재배치**라고 한다. `예) MS-DOS의 COM 프로그램은 컴파일 시간에 바딩된 절대 코드다.`

  **2. 적재시간**

 ****컴파일 과정에서 절대 주소를 알 수 없다면 컴파일러는 재배치 가능한 상대 주소를 생성한다. 상대 주소는 프로그램 시작 주소가 0으로 생성되므로 최종 바인딩은 적재시간까지 연기된다. 이와 같은 과정을 **정적 재배치**라고 한다.

 **3. 수행시간**

한 프로그램이 동일한 장소에서 작동한다면 적재시간 가정에서 바인딩할 수 있다. 그러나 만약. 프로세스가 실행되는 도중에 메모리의 한 세그먼트에서 다른 세그먼트로 이동한다면 바인딩은 수행시간까지 연기되어야 한다.

### 동적 적재(Dynamic Loading)

- 주소 바인딩 시간을 최대한 늦추어서 실행되기 직전에 주소를 확정하면 시스템 운영과 메모리 활용에 도움을 줄 수 있다. 이를 위해 동적 적재 기법이 제안되었다.
- 모든 루틴은 호출될 때까지 메모리 내에 적재되지 않고 재배치 가능한 형태로 디스크에 저장되어 있다.
- 호출 루틴이 다른 루틴을 호출할 필요가 있을 때, 메모리에 적재되어 있는지 검사
- 만약 적재되어 있지 않다면, 재배치 가능 연결적재기(로더)는 요구된 루틴을 메모리로 적재하기 위해 호출하면서 프로그램의 주소 테이블을 갱신하여 이러한 변화를 반영한다. 이러한 과정을 동적 적재라고 한다.

### 중첩(Overlay)

- 프로세스의 크기는 실제 메모리의 크기로 제한되는데 이러한 크기 제한을 해결하기 위해 중첩기법을 사용한다.
- 중첩은 운영체제 영역과 메모리 공간의 일부 영역에 프로그램 실행에 반드시 필요한 명령어와 데이터를 저장한다.
- 나머지 영역, 오버레이 드라이브 영역에는 실행시간 동안에 필요한 각종 사용자 코드 등을 적재하여 필요한 시기에 해당 프로그램을 불러들여 수행한다.

### 프로세스 교체

- 다중 프로그래밍 환경에서 프로세스는 사용자 프로그램이 끝날 때까지 메인 메모리에 저장됨을 원칙으로 지켰다.
- 그러나 라운드 로빈 알고리즘이나 우선순위에 바탕을 둔 프로세서 알고리즘에서 적합하지 않음

## 연속 메모리 할당

### 단일 사용자 메모리 할당

- 첫번째 방법, 사용자 프로그램으로 상위 주소에 적재하지 않고 기준 레지스터로부터 내려가는 상위 메모리에 적재하는 방법
- 두번째, 수행할 때까지 주소 바인딩을 연기, 기준 레지스터에 있는 값은 사용자 프로세스가 메모리로 보내질 때 생성되는 주소값에 더해진다.
- 단일 사용자 연속 메모리 할당 시스템은 단순하고 사용자 공간이 확(운영체제 부분이 작자도 가능)되는 장점이 있다.
- 전반적으로 자원의 낭비(프로그램이 차지하고 남은 부분에 대한 활용이 불가능하다는 단점이 있다.

### 고정 분할 다중 프로그래밍

- 메모리를 여러 개의 고정된 크기로 분할(정적 분할)하여, 분할된 각 메모리는 하나의 프로세스가 할당된다.
- 물리 주소는 분할 기준 레지스터(PBR) 값에 논리 주소를 더하여 생성된다.
- 분할 영역 크기보다 논리 주소가 작아야 하므로, 내부 단편화가 발생한다.
- 예를 들면, 2KB, 6KB, 12KB로 분할한다면 세 개의 작업 큐가 생성되고, 크기에 맞게 프로세스가 큐에 할당되어 처리된다.
- 다른 큐가 비어있더라도 다른 큐를 사용할 수 없어 모든 작업을 하나의 통합 큐에 넣고 운영하는 방법도 있다.

### 고정 분할 다중 프로그래밍에서의 단편화

- 단편화는 사용자 작업의 크기가 지정된 분할에 정확히 맞지 않거나 분할이 너무 작아서 대기 중인 작업 중 하나도 맞는 것이 없는 상태를 말한다.
- 고정 분할은 효율적인 메모리 운영이 가능하나 기억 장소의 낭비를 해결하지 못한다.
- 기준 레지스터와 한계 레지스터를 이용하여 분할당 영역을 보호할 수 있다.

   **기준 레지스터** : 가장 작은 합법적인 물리 메모리 주소(300040)

   **한계 레지스터 :** 프로그램 영역이 저장되어 있는 범위의 크기(120900)를 저장

`기준 레지스터 <= 프로세서 주소 < 기준+한게 레지스터`

### 가변 분할 다중 프로그래밍

- 고정된 경계를 없애고 각 작업이 필요한 만큼 메모리를 할당하는 방법이다.
- 기준 레지스터와 한계 레지스터를 사용하는데, 한계 레지스터는 프로세스 크기만큼의 영역에 저장한다.

프로세스의 논리주소 공간 → 한계 레지스터보다 작은가 → 기준 레지스터와 논리주소의 합 → 프로세스의 물리주소 공간

- 가변분할 당에서는 운영체제 메모리의 어떤 부분을 사용할 수 있고 어떤 부분이 사용되고 있는가를 알 수 있는 테이블을 유지
- 가변분할 할당의 문제는 요그된 크기 n을 사용가능공간에 어떻게 할당하느냐다.

### 메모리 배치 기법

**1. 최초 적합 기법**

- 프로세스는 사용가능공간 리스트에서 충분히 큰 첫번째 공백 분할 공간에 할당된다.
- 검색은 사용가능공간리스트의 맨 앞이나 이전의 최초 적합 검색이 끝난던 곳에서 시작한다.
- 검색을 빨리 끝낼 수 있지만 공간 효율이 떨어질 수 있다.

**2. 최상 적합 기법**

- 프로세스가 들어갈 수 있는 충분히 큰 사용가능공간 중에서 가장 작은 크기의 사용 공간에 할당한다.
- 공간 리스트가 크기 순서로 정렬되어 있지 않으면 전체 리스트를 검색해야하고, 사용가능공간에 대한 지속적인 정렬과정이 필요하여 비효율적일 수 있다.

**3. 최악 적합 기법**

- 작업을 가장 큰 사용가능공간에 할당한다. 정렬이 필요하다.
- 가장 작은 또 다른 사용가능공간을 만들어 내는 최상 적합보다 메모리 활용면에서 더 유용하다.

일반적으로는 최초 적합이 최상 적합보다, 최상 적합이 최악 적합보다 더 좋다.

### 가변 분할에서의 메모리 보호

- 메모리를 보호하기 위해 상한값과 하한값을 계산하기 위해 기준 레지스터와 한계 레지스터를 사용한다.

`기준 레지스터 ≤ 프로세서 주소 ≤ 기준+ 한계 레지스터`

### 외부 단편화

- 가변 분할 알고리즘은 외부 단편화 문제가 발생하며, 프로세스들이 메모리에서 제거되고 새로운 프로세스가 적재될 때 사용가능공간은 작게 나누어 진다.
- 작업보다 많은 공간이 남아 있더라도 실제로 그 작업을 받아 들이지 못하는 경우를 외부단편화라고 한다.
- 이런 낭비의 해결방안으로 통합(병합)과 압축 방법이 있다.

### 통합

- 공백의 통합은 하나의 작업이 끝났을 때 기억 장소가 비어 있는 다른 기억 장ㅅ와 인접되어 있는지를 점검하며 하나의 공백으로 합하는 과정이다.
- 메모리 전반에 흩어져 있는 비어있는 공간을 모두 사용가능공간으로 통합하는 것은 어렵다.

### 압축

- 메모리 내용들을 적절히 움직여서 모든 사용가능메모리를 하나의 큰 블록으로 만드는 것이다.
- 프로세스들이 새로운 위치에서 수행되기 때문에 모든 내부 주소들이 재배치 될 수 있어야 한다.
- 재배치가 정적이면서 어셈블리나 적재할 때에 실행한다면 압축을 수행할 수 없다.
- 압축은 동적인 경우만 가능하고 수행시간에 이루어지는 것이 특징이다.
- 압축을 하는 방법에 따라 비용의 차이가 있으므로 최적의 압축 정책을 선택하는 것은 어렵다.
- 단점으로는 압축하는 동안 시스템은 모든 일을 멈춰야 한다.
- 메모리에 있는 작업들을 이동시켜야 하므로 프로그램 적재 시 제거되는 재배치 관련 정보를 액세스 가능한 형태로 보관해야한다.
- 압축 작업이 자주 요구되어 시스템 자원의 소모가 크다.

### 버디 시스템

- 단편화란 기본적으로 자원이 하나의 연속된 단위로 존재하는 것이 아니라 부분적으로 나뉘어 흩어져 있는 상태를 말한다.
- 자원 할당 과정에서 발생하는 단편화는 메모리를 배당하고 회수하는 과정에서 아무도 사용하지 않고 흩어진 자원의 사용이나 배정이 불가능한 상태를 말한다.
- 가능한 적당하게 메모리 요청을 만족하도록 메모리를 여러 부분으로 나누는 메모리 할당 알고리즘이다. 이 시스템은 메모리의 크기를 절반씩 분할을 하면서 가장 잘 맞는 크기의 메모리를 찾는다.

## 분산 메모리 할당

- 외부 단편화의 해결 방법으로 압축은 메모리 할당을 변화시켜 연속적인 공간을 만들어 사용할 수 있었지만 프로세서 시간을 낭비하는 결과를 가져왔으며 비용 부담이 크다.
- 이러한 압축 과정에서 제기된 동적 재배치 기능은 외부 단편화를 해결하면서 내부 단편화를 최소화하는 기법으로 발전하였는데, 이 기법이 분산 메모리 할당 기법이다.
- 분산 메모리 할당 기법은 이전 메모리 할당 기법의 문제들을 해결하기 위해 한 프로세스의 기억 장소에 불연속 공간을 허용한다.
- 페이징 기법, 세그먼트 기법, 요구 페이징 기법 등으로 나눌 수 있다.

### 페이징 기법

- 페이징 기법은 처리할 작업을 동일한 크기의 페이지로 나누어 처리한다는 것 이다.
- 실제 메모리를 프레임이라 불리는 고정 크기 블록으로 나누고, 각 프로세스도 페이지라 불리는 동일한 크기의 작고 고정된 크기의 영역으로 분할한다.
- 이 때, 페이지라고 불리는 프로세스의 영역들이 프레임이라고 불리는 메모리 영역에 할당된다.
- 논리 메모리는 페이지와 같은 크기 블록으로 나누어지고, 보조기억장치는 프레임과 같은 크기로 나누어 진다.
- 페이지를 관리하기 위해서 다음이 준비되어야 한다.

  1. 프로그램에 소요되는 페이지를 결정하여 페이지 번호를 부여한다.

  2. 프로그램을 적재하도록 메모리의 빈 프레임을 조사하여 위치를 파악한다.

  3. 프로그램의 페이지를 빈 페이지 프레임에 적재하도록 준비한다.

- 페이지 프레임 간에 외부 단편화 문제가 발생하지 않지만 페이지가 여러 위치에 분산되기 때문에 페이지 위치 정보 등을 페이지 관리가 복잡해져 내부 단편화가 발생된다.
- 외부 단편화는 발생하지 않지만, 내부 단편화는 발생한다.

### 페이징 시스템 하드웨어

- 논리 주소 = 페이지 번호(p) + 변위 (d)
- 물리 주소 = 기준 주소(메인프레임 번호) (f) + 변위(d)
- 페이지 테이블(PMT, Page Map Table) = 페이지 번호(p) of 기준 주소(메인프레임 번호) (f)
- 논리 주소 → 페이지 테이블 맵핑 → 물리 주소
- `변위 : 페이지 시작으로부터 얼마나 떨어져 있는가, 페이지 프레임 크기 보다 작다.`

### 다중 계층 페이지

- 논리 주소에서 물리 주소로 변환하는 과정에서 가장주소공간의 크기가 커질수록 페이지 테이블의 크기가 증가하므로 메인 메모리에 보다 큰 적재 공간이 요구된다.
- `예) 32비트 프로세스는 4G(2^32) 까지 사용할 수 있고, 페이지 크기를 4KB 라면, 페이지 테이블이 1,048,576개나 필요하다.`
- 이러한 문제를 해결 하기 위해 페이지 테이블을 n-단계 계층 구조로 구성하여 전체 가상주소공간 중 실제 참조할 페이지들이 존재하는 영역에 대해서만 단계별 페이지 테이블을 설정하여 처리한다.
- 하위(0~11) 12 비트는 변위로 중간(12-21) 비트는 페이지 테이블 색인, 상위(22~31)비트는 페이지 항목(디렉토리) 색인을 나타낸다.

### 페이지 스케줄링

- 프로세스가 수행되기 전에 준비 큐에 도착했을 때, 프로세스의 크기는 페이지 단위로 표현
- 장기 스케줄러는 할당되징 않은 빈 페이지 프레임 리스트를 유지
- 프로세스가 요구하는 n개 페이지가 프레임에 할당될 수 있다면 프로세스를 할당
- 프레임 번호는 페이지 테이블에 기록된다.

### 페이지 테이블의 구현

- 페이지 테이블은 고속으로 처리가능해야 됨
- 레지스터의 경우 수백만 개의 페이지 항목이 존재할 수 있으므로 적합하지 않다.
- 따라서 메모리에 페이지 테이블을 유지하고, 페이지 테이블 기준 레지스터(PTBR)가 페이지 테이블을 지시하도록 한다.
- 페이지 테이블을 액세스 하기 위해 PTBR와 페이지 번호를 통해 메모리에 있는 페이지 테이블을 색인해야 한다.
- 이러한 엑세스는 속도가 느려지는 문제점이 있음
- 이러한 문제점을 해결하기 위해 연관 레지스터 또는 변환 우선참조 버퍼(TLBS)를 이용한다.
- 사상 방법에 따라 주소변환은 다음과 같이 구별된다.

**- 직접 사상** : 페이지 사상표를 직접 이용하여 동적 주소 변환

**- 연관 사상** : 페이지 변환 정보를 연관 기억장치에 저장한 연과 사상표를 이용하여 동적 주소 변환

**- 연관/직접 사상** : 연관 사상표에는 가장 최근에 참조된 페이지 항목만 보관하고 나머지는 페이지 사상표에 수록하여, 연관 사상표에 없을 때는 직접 사상 기법으로 변환

### 공유 페이지

- 페이징 시스템은 시분할 환경에서 중요한 공통된 코드를 공유할 수 있다.

### 메모리 보호

- 메모리 보호는 페이지 테이블 속에 있는 한 개의 보호용 비트에 의해 수행되며 각 페이지와 연관되어 있다.
- 1비트는 한 페이지가 읽기/쓰기 또는 읽기 전용 임을 정의할 수 있다.
- 쓰기 기능을 읽기 전용 페이지에 수행하지 않는다는 것을 검증할 수 있음

## 세그먼트 메모리 관리 기법

- 세그먼트 메모리 관리 기법은 사용자 관점을 지원하는데, 메모리를 크기가 변할 수 있는 세그먼트라는 단위 모음으로 생각한다.
- 고정 크기를 갖는 페이징과는 다른 메모리 기법이다.
- 일반적으로 프로그램을 구성하는 서브루틴, 프로시저, 함수, 모듈 등의 각각 다른 크기를 갖는 세그먼트로 나누고 각 세그먼트는 연관된 기능을 수행하는 하나의 모듈 프로그램으로 생각한다.

### 세그먼트 메모리 할당

- 메모리의 사용자 관점을 지원하는 메모리 관리 기법으로 논리 구조 공간을 세그먼트의 모임으로 인식한다. 페이징과 비슷한 분산 메모리 할당의 기법이나 세그먼트 크기가 다르기 때문에 메모리가 일정한 크기의 페이지 프레임으로 나누어지지 않고 동적분할 기법으로 메모리를 할당하게 된다.

### 페이지화된 세그먼트 메모리 할당

- 페이징은 내부 단편화 현상을 갖고 있으나 메모리를 효율적으로 사용할 수 있으며 세그먼트 기법은 외부 단편화를 갖고 있으나 가변적인 데이터 구조와 모듈 처리, 그리고 공유와 보호의 지원이 편리하다는 장점이 있다. 이러한 장단점을 해결하기 위한 방법이 페이지화된 세그먼트 메모리 할당기법이다. 이 기법은 세그먼트를 페이징하여 외부 단편화를 제거하면서 할당 과정을 해결했다.

# 가상 메모리

## 가상 메모리 개념

- 프로그래머나 사용자들이 디스크라는 부르는 커다란 메모리 공간을 가상의 메모리 공간으로 사용하는 기법

### 가상 메모리 등장 배경

- 메인 메모리에서 사용자와 논리 메모리를 물리적으로 분리하여 프로그래머에게 메인 메모리보다 훨씬 큰 가상의 메모리를 제공한다.
- 페이징 시스템으로 가상 메모리 시스템을 구현하여 메인 메모리를 보다 효율적으로 사용할 수 있어 더 많은 작업을 메인 메모리에 적재할 수 있다.
- 대부분의 프로그램은 프로그램 전체가 동시에 실행되지 않기 때문에 부분적인 적재만으로도 프로그램을 실행시킬 수 있는 특징을 이용한 메모리 관리 기법
- 가상 메모리의 장점으로는 프로그래밍 작업이 쉽다. 공간의 제약이 없으므로 중첩을 작성할 필요가 없다.
- 공간이 부족해도 부분 적재가 가능하여 많은 작업을 실행할 수 있기 때문에 프로세서의 이용률과 처리율은 향상될 수 있다.
- 문제점으로는 메모리와 디스크 공간 사이의 이동량 증가에 따른 교체 공간의 확보, 어느 시기에 페이지를 적재하고 다시 복귀시킬 것인가에 대한 페이징 알고리즘 결정, 페이지 부재에 대한 처리 방안 등에 적절한 해결 방법이 요구된다.
- 프로세스가 참조하는 가상 주소(논리 주소)를 물리적 주소로 변환하는 사상(Mapping)이 빨리 이루어져야 한다.
- 사상 수단 중 동적 주소 변환(DAT, Dynamic Address Translation) 기법은 인위적 연속성 성질을 갖고 있다.
- `인위적 연속성 : 가상 주소 공간상의 연속적인 주소가 메인 메모리에서 연속적일 필요가 없다는 뜻`

### 블록 사상

- 동적 주소 변환 기법은 주소사상테이블(Address Mapping Talbe)을 유지해야 한다.
- 사상이 바이트(Byte) 또는 워드(Word) 단위로 이루어지면 주소사상테이블 유지를 위한 정보량이 커지므로 주소를 블록 단위로 처리하는 기법이 나타났다.
- 시스템이 블록의 위치만을 유지하고 추적하기 때문에 효율적이다.
- 블록의 크기가 커질 수록 내부 단편화 문제가 발생할 수 있다.
- 블록이란 가상 메모리의 분할 단위이다.

## 요구 페이징

- 요구 페이징 기법은 일반적인 가상 메모리 체계로 스왑 기법을 사용하는 페이징 시스템과 비슷하며, 프로그램을 실행하기 위해 프로그램의 일부만을 메인 메모리에 적재한다.
- 모든 프로세스를 메모리에 직접 적재하지 않고 지연 교환기(Lazy Swapper)를 사용하여 적재
- 지연 교환기는 페이지 요구가 있을 때 요구 페이지를 메모리에 교체하여 동시에 모든 페이지를 교체하지는 않는다.

### 요구 페이징의 기본 개념

- 동적 주소 변환에서는 가상 메모리와 메인 메모리 사상을 사상테이블로 표시
- 페이지 기법에서는 페이지 테이블로 표시한다.
- 요구 페이징은 페이지 정보를 표시하기 위해 타당 또는 비타당 비트를 페이지 테이블에 추가한다.
- 비트가 타당 비트(v)로 설정되어 있다면 해당 페이지가 물리적 메모리에 있다는 것을 의미
- 비트가 비타당 비트(i)로 설정되어 있다면 페이지는 보조기억장치에 있다는 것을 의미
- 프로그램이 메모리에 저장되어 있지 않는 페이지를 사용하려고 하면 페이지 부재(Page Fault)가 발생
- **요구 페이징 기법의 장점**

   - 요구 페이징 시스템은 다중 프로그래밍의 정도를 증가시키고 액세스되지 않은 페이지를 로드하지 않으므로 다른 프로그램들을 위해 메모리르 절약할 수 있다.

   - 프로그램을 시작할 때 적재 지연이 적다

   - 적은 수의 페이지를 읽기 때문에 초기 디스크 오버헤드가 적다

   - 보호 오류를 페이지 오류로 사용할 수 있기 때문에 페이징에 필요한 별도의 하드웨어 지원이 필요하지 않다.

   - 적재된 페이지들 중 하나가 수정될 때까지 페이지들은 여러 프로그램에 의해 공유되므로 공유 페이지 기술은 보다 많은 자원을 절약한다.

   - 프로그램을 실행할 충분한 메모리가 없는 시스템에서도 대용량 프로그램을 실행할 수 있다.

- **요구 페이징 기법의 단점**

   - 개별 프로그램들은 페이지에 처음 액세스할 때 약간의 지연이 발생한다. 

   - 낮은 비용, 낮은 성능의 시스템에 실행되는 프로그램은 페이지 대체를 지원하느 메모리 관리 장치가 없다.

   - 메모리 관리가 복잡하다.

### 페이지 성능

- 페이지 부재 확률 p (0 ≤ p ≤ 1)
- 메모리 엑세스 접근 시간 Ma
- `유효액세스 시간 = (1-p) * Ma + p - (페이지부재시간)`
- 유효액세스시간은 페이지 부재율에 비례한다.

### 페이지 대치

- 물리적 메모리에 비어있는 프레임이 없다면 페이지를 대치시켜야 한다.
- 페이지 대치의 엑세스 방식은 다음과 같다.
1. 비어 있는 프레임이 없다면 현재 사용하지 않는 프레임을 찾는다. 사용하지 않는 프레임이 있다면, 발견한 프레임을 비우기 위해 프레임의 내요을 보조기억장치에 저장한다.
2. 페이지가 메모리에 더 이상 존재하지 않는다는 것을 알려주기 위해 페이지 테이블을 변화(비타당비트 전환)시킴으로써 프레임은 비게 된다.
3. 원하는 페이지를 디스크로부터 읽어 프레임에 저장한다.
4. 새로운 페이지를 위하여 페이지 테이블을 수정한다.

- 페이지 대치 과정은 다음과 같다.
1. 디스크에서 요구한 페이지의 위치를 확인한다.
2. 빈 프레임을 찾는다.
3. 빈 프레임이 발견되면 빈 프레임을 사용
4. 빈 프레임이 발견되지 않으면 희생 프레임을 선정하기 위하여 페이지 대치 알고리즘을 사용
5. 희생 페이지는 디스크에 기록, 페이지와 프레임 테이블을 수정
6. 요구된 페이지를 읽어 들이고 페이지와 프레임 테이블 수정
7. 사용자 프로세스를 시작

- 이러한 페이지 부재 대치 과정은 스와핑하여 액세스 처리 시간이 증가하게 된다.
- 이러한 부담은 수정된 비트를 활용하여 감소시킬 수 있다.

## 페이지 대치 알고리즘

- 일반적으로 페이지 부재율이 가장 낮은 알고리즘을 기본으로 선택한다.

### 페이지 부재와 프레임 개수

- 일반적으로 프레임 수가 증가하면 페이지 부재수가 감소한다.

### 선입선출 대치 알고리즘

- 가장 오래된 페이지부터 대치
- 메모리에 있는 모든 페이지는 선입선츌 큐(FIFO)에 의해 관리
- **Belady’s Anomaly**라고도 하는데 할당되는 페이지 프레임의 수가
늘어나는데 페이지 부재는 더 늘어나는 이상 현상

### 최적 페이지 대치 알고리즘

- 모든 페이지 알고리즘 중 페이지 부재율이 가장 낮다.
- 페이지 중 가장 늦게 다음에 사용될 페이지를 교체한다.
- **최소 작업 우선 스케줄링(SJF)**와 마찬가지로 미래의 정보를 알아야 되기 때문에 현실적으로 어려움

### 최근 최소 사용 알고리즘(LRU, Least Recently Used)

- 최적 페이지 대치 알고리즘의 근사치를 사용
- 가장 오랫동안 사용하지 않는 페이지를 교체
- 참조된 페이지에 대한 시간 기록을 해야하는 오버헤드 발생

### 최근 최소사용 근접 알고리즘

**부가된 참조비트 알고리즘**

- 각 페이지에 8비트 길이의 참조 비트 부여
- 페이지가 사용될 때마다 최상위 비트를 1로 바꾸고 오른쪽으로 한자리씩 시프트
- 값이 00000000이면 한번도 사용된 적이 없는 페이지
- 값이 11111111이면 매번 사용된 페이지
- 값 11000100은 01110111보다 최근에 사용된 페이지
- 이를 통해서 어떤 페이지를 내보낼 것인가를 결정

**시계(2차적 기회 대치) 알고리즘**

- 모든 페이지에 1비트의 참조 비트 부여
- 페이지가 사용될 때마다 참조 비트를 0에서 1로 전환
- 참조 비트가 0인 페이지를 내보낼 페이지로 결정
- 참조 비트가 1인 페이지는 참조비트를 0으로 바꾸고 한번
의 기회를 더 줌
- 다음 검사에서 참조 비트가 0이면 대치 대상이 되고 그
동안 또 사용되어 1로 되어 있으면 다시 0으로 바꿈

**최소사용 빈도수 알고리즘(LFU), Least Frequently Usd)**

- 참조 횟수가 가장 적은 페이지를 교체
- 한 페이지가 초기에는 많이 사용됐지만 그 후로 다시 사용하지 않으면 큰 계수를 가져서 더 이상 필요하지 않아도 메모리 속에 남아 있음
- 이를 해결하기 위해 일정한 시간 간격으로 하나씩 오른쪽으로 쉬프트해서 지수적으로 감소시키는 방법이 있다.

**최대사용 빈도수 알고리즘(MFU, Most Frequently Used)**

- 가장 작은 계수를 가진 페이지는 방금 들어온 것으로 아직 사용되지 않았기 때문에 앞으로 사용확률이 높다고 가정한다
- 그리고 가장 많이 사용된 페이지를 교체

**페이지 버퍼링**

- LRU와 시계 알고리즘은 FIFO 대치 알고리즘 보다 성능은 좋으나 복잡성과 페이지 교체로 인한 오버헤드가 큼
- 페이지 버퍼링은 선택된 페이지를 즉시 교체하지 않고 잠시 동안 메모리에 유지한다.

## 프레임 할당 알고리즘

### 최소 프레임 수

- 프로세스들에게 페이지 프레임을 할당하는 것은 가용 프레임 수에 전
적으로 의존
- 프로세스들에게 할당되는 프레임 수가 줄어들면 페이지 부재율 상승
- 페이지 부재는 페이지 대치 알고리즘의 실행을 유도하고 페이지 교체를 수반하므로 프로그램 실행 속도 저하 유발
- 프로세스들에게 많은 페이지 프레임을 할당할 수도 없음
- 프로세스들이 많은 페이지 프레임을 갖고 있으면 다중 프로그밍
의 정도가 떨어져서 이 또한 시스템 성능 하락의 요인이 됨
- 프로세스별로 반드시 확보해야 할 페이지 프레임의 수가 보장되어야
함
- **균일 알고리즘** : 프로세스의 길이와 무관하게 일정한 수의 프레임 할당
- **비례 할당 알고리즘** : 전체 프레임 수와 프로세스들의 길이를 고려하여 프레임 차
등 할당

## 프로세스 적재 정책

### 스레싱(Thrashing)

- 프로세스가 기본적으로 확보해야 할 페이지 프레임의 수가 충분하지 못하여 빈번하게 페이지 부재(page fault)가 발생하는 현상
- CPU 이용률이 떨어지면 프로세스의 이용률을 높이기 위해 새로운 프로세스를 도입하여 다중 프로그래밍 정도를 높임 → 새로운 프로세가 수행 중인 프로세스의 페이지를 빼앗아 페이지 부재가발생함 → 결가적으로 프로세스의 이용률을 더욱 낮아지고 프로세서 스케줄러는 이용률 높이기 위해 다중 프로그래밍의 정도를 더 높이게 되지만 프로세스의 실행은 점점 늦어짐
- **스레싱 예방 :** 최적의 페이지 프레임 수 제공

### 지역성

- 국부성이라고도 함
- 실행 중인 프로세스에 의해 나타나는 특성으로, 프로세스들은 실행 기간 동안 메모리 내의 정보를 균일하게 액세스하는 것이 아니라 페이지 중 일부를 선호하여 지역적인 부분만을 집중적으로 참조하는 현상
- 지역성의 예
• 함수 하나가 새롭게 호출
• 반복문이 실행되기 시작
• 배열이 참조되기 시작
- 지역성의 종류
• 시간적 지역성 : 참조된 기억장소는 가까운 미래에 다시 참조
• 공간적 지역성 : 참조된 기억장소 인근 주소를 계속 참조
- 지역성이 왜 중요한가?
• 몇 개의 페이지 프레임을 할당할 것인가를 결정하는 단초가 됨

## 입출력 시스템

### 입출력 모둘

- 입출력 채널(I/O channel) 또는 입출력 프로세서

      프로세서를 대신하여 입출력 모듈이 입출력과 관련된 복잡한 일을 처리

- 입출력 제어기(I/O Controller) 또는 장치 제어기(Device
Controller)

     입출력 모듈이 단순히 프로세서의 입출력과 관련된 일을 담당

- 입출력 모듈의 필요성

     프로세서와 입출력 장치는 실행 속도가 다름

     실행 속도가 다른 여러 장치에 대한 조정을 하지 못하면 데이터 손실이 발생함

     입출력 장치들은 시스템 버스에 연결되지 않고 입출력 모듈을 통해 연결됨

     입출력 장치에 따라 제어 방식과 운영 방식이 다르기 때문

### 입출력 모듈의 기능

- 입출력 장치의 제어
• 입출력 모듈이 외부장치의 타이밍과 데이터 형식, 기계적인세부사항을 처리해주기 때문에 프로세서는 단순히 파일 열기,파일 닫기 명령만을 이용하여 장치 제어 가능
- 프로세서와의 통신
• 프로세서로부터 수행해야 할 명령어를 전달받고, 관련된 메시지를 인식하기 위한 기능 제공
• 명령어 해독 – 데이터 교환 – 상태 보고 – 주소 인식
- 데이터 버퍼링
• 주기억장치 또는 프로세서와 입출력장치의 속도 차를 해결하기 위해 입출력 데이터를 위해 주억장치의 일부를 제공
- 오류 검출
• 종이 걸림, 불량 디스크 트랙 등과 같은 기계적인 결함, 전송중에 발생하는 전송 결함 등을 해결
• 전송 결함 해결을 위해 가장 일반적으로 사용하는 방법은 패리티 비티

### 프로세서와 입출력장치의 속도 조절 방식

**1. 프로그램 제어 입출력**

- 폴링(polling) 방식이라고도 함
- 프로세서 내부에 있는 입출력 데이터와 주소 레지스터를 입출력 모듈과 연결한 형태로 주소 레지스터와 버스 사이에서 데이터를 직접 전송할 수 있는 가장 간단한 형태
- 프로세서보다 상대적으로 느린 입출력장치의 입출력 동작 상태를 확인하기 위해 상태 비트를 주기적으로 검사

**2. 인터럽트 기반 입출력**

- 입출력장치가 작업을 완료한 다음에 작업과 관련된 상태와 결과를 메모리에 저장하고, 인터럽트를 발생시켜 프로세서에 통보
- 프로그램 제어 입출력 방식보다 빠름

![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/6495ca73-8d73-4ee4-b32c-a2ee006ee1a5/Untitled.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/6495ca73-8d73-4ee4-b32c-a2ee006ee1a5/Untitled.png)

**3.DMA(Direct Memory Access) 입출력**

- 프로그램 제어 입출력과 인터럽트 기반 입출력 방식은 데이터 전송과 관리를 프로세서가 담당
- 프로세서 부담 가중
- DMA 방식은 프로세서가 읽기 및 쓰기 정보, 입출력 주소 및 메모리 주소, 길이 등을 DMA 제어기에 주면 DMA 제어기가 직접 처리

![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/d5c79bd4-cd97-4b6a-b050-14f857468ad7/Untitled.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/d5c79bd4-cd97-4b6a-b050-14f857468ad7/Untitled.png)

### **디스크 접근 시간(Disk Access Time)**

- 디스크 상의 원하는 위치로 접근하는데 소요되는 시간

 `Access Time = 탐색 시간(Seek Time) + 회전지연시간(Rotational Latency) + 전송 시간 (TransferTime)`

- 탐색 시간은 원하는 데이터가 있는 실린더(또는 트랙)를 찾는데 소요되는 시간
- 회전지연시간은 해당 실린더에서 원하는 섹터를 찾는데 소요되는 시간
- 전송 시간은 실제 데이터를 전송하는데 소요되는 시간
- 디스크 접근 시간을 줄이는 방법
• 탐색 시간을 줄이는 방법
• 회전지연시간을 줄이는 방법
• 일반적으로는 탐색 시간의 비중이 크기 때문에 디스크 스케줄링 알고리즘은 헤드의 이동 거리를 줄이는 쪽으로 발전해왔음
• 최근 회전지연시간을 줄이려는 노력이 생김

### 디스크 헤드 스케줄링

### 선입 선처리 스케줄링(FCFS : First Come First Served)

- 도착한 순서대로 서비스
- 단순하게 적용할 수 있는 장점은 있으나 디스크 헤드의 이동이 많아서 효율적이지 못함

### 최소 탐색 시간 우선 스케줄링(SSTF : Shortest Seek Time First)

- 현재의 헤드 위치에서 가장 가까운 위치로 이동하여 서비스
- 효율적인 장점은 있지만 현재 헤드의 위치에서 먼 트랙에 있는 작업은 기아(starvation)에 빠질 수 있음
- 현재 위치에서 가장 가까운 트랙으로 이동하는 것이 가장 효율적이라는 보장은 없음

### 스캔 스케줄링(SCAN)

- 현재 디스크 헤드의 진행 방향으로만 이동하고 끝에 다다랐을 때 방향을 바꾸어 서비스
- 엘리베이터 알고리즘이라고도 함

### 순환 스캔 스케줄링(C-SCAN)

- 현재 디스크 헤드의 진행 방향으로만 이동하고 끝에 다다랐을 때 다시 반대쪽 끝으로 와서 동일한 방향으로 서비스

### 룩 스케줄링(LOOK, C-LOOK)

- 현재 디스크 헤드의 진행 방향으로만 이동하고 더 이상의 요청이 없을 때 이동 방향을 바꾸어 서비스
- 룩(Look)이란 진행 방향으로 이동하기 전 요청이 있는지 없는지를 확인하는 작업

### 디스크 스케줄링 알고리즘의 선택

- 일반적으로는 SSTF 알고리즘이 가장 효율적으로 알려져 있음
• 스캔 또는 C-스캔은 디스크를 많이 사용하는, 입출력 작업이 빈번한 시스템에 적합
- 어느 알고리즘이든 알고리즘의 성능은 요청되는 서비스의 형태와 요청 수에 의존
• 디스크 사용 빈도가 적은 경우는 알고리즘 간의 성능 차이가 거의 발생하지 않음
• 이런 경우는 FCFS가 가장 효율적임
- 디스크 서비스의 요청은 파일 할당 방식과도 밀접함
• 연속적인 파일 할당 방식은 디스크의 인접한 공간에서 자주 입출력이 발생하기 때문에 디스크 헤드의 이동은 적으나 공간 활용도가 낮음
• 링크 파일이나 색인 파일의 경우에는 디스크 전체에 걸쳐 파일이 수록되기 때문에 디스크 헤드 이동 거리는 길지만 디스크 공간 활용도는 효율적임

## RAID

- RAID는 여러 개의 하드 디스크를 하나의 논리적 가상 디스크로 구성하여 하나의 논리적 대용량 저장장치로 사용할 수 있는 기법이다.
- 데이터를 여러 개의 하드 디스크에 분할, 저장하여 전송속도를 향상시키며 시스템 가동 중 생길 수 있는 디스크의 오류를 시스템 정지 없이 교체 가능하다.

### RAID 0

- 일명 stripping이라고도 불리는데 strip이라고 하는 일정한 크기의 섹터 또는 물리적 블록 단위로 나누어 연속적인 배열 첨자와 대응되도록 순환 할당
- 논리적으로 연속된 strip들의 집합을 stripe라고 함
- 데이터를 중복 저장하지는 않으므로 특정 디스크에서 장애가 발생하면 데이터는 손실됨
- 데이터 손실이 다소 발생해도 시스템 효율에 크게 지장을 주지 않는 동영상 시스템과 같은 응용에 적합

### RAID 1

- 일명 mirroring이라고도 불리는데 RAID0과 같이 기본적으로 stripping을 사용하면서 미러 디스크(mirror disk)를 가짐
- 미러 디스크란 복사본을 말함
- 읽기 동작은 동일한 내용을 가진 2개의 디스크에서 병렬 처리되므로 성능 향상
- 한쪽 디스크에서 장애가 발생해도 다른 한쪽 디스크를 사용할 수 있으므로 시스템 안정성이 향상되지만 디스크 공간이 두배 이상 필요함
- 시스템 드라이브와 같은 중요한 파일을 운영할 때 적합

### RAID 2

- 해밍 코드를 이용해서 패리티 비트(parity bit)를 별도로 저장해서 오류 검증
- 기본적으로는 파일을 분할해서 분산 저장하고, 패리티 비트만 저장하고 있는 디스크의 정보를 통해 오류가 있는지를 확인
- 최근에는 SCSI 드라이브에도 자체적인 오류 검출 능력을 갖고 있기 때문에 RAID2는 보편적으로 사용되는 계층은 아님

### RAID 3

- 오류 검출과 수정을 위해 별도의 드라이브 한 개를 패리티 드라이브로 사용
- 내장된 오류 정정 코드 정보는 오류를 감지하는데 사용하며, 데이터 복구는 다른 드라이브에 기록된 정보의 XOR을 계산하여 수행
- 대형 레코드가 많이 사용되는 단일 사용자 시스템과 다량의 데이터 전송이 요구되는 CAD나 이미지 작업에 적절한 계층

### 참조

구현회, 그림으로 배우는 구조와 원리 운영체제

[http://contents.kocw.or.kr/KOCW/document/2015/cup/weonsunghyun/1.pdf](http://contents.kocw.or.kr/KOCW/document/2015/cup/weonsunghyun/1.pdf)